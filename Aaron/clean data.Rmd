---
title: "Untitled"
author: "Aaron Owen"
date: "11/5/2017"
output: html_document
---

```{r}
library(dplyr)
```

```{r}
iowa = read.csv("train.csv", stringsAsFactors = F)
iowa2 = read.csv("train.csv", stringsAsFactors = F)
TEST = read.csv("test.csv", stringsAsFactors = F)

# removing the index column
iowa = iowa[-1]
iowa2 = iowa2[-1]
TEST = TEST[-1]

```

```{r}
# Convert to categorical TRAINING set
iowa$MSSubClass = as.factor(iowa$MSSubClass)
iowa$MoSold = as.factor(iowa$MoSold)
iowa$YrSold = as.factor(iowa$YrSold)

iowa2$MSSubClass = as.factor(iowa2$MSSubClass)
iowa2$MoSold = as.factor(iowa2$MoSold)
iowa2$YrSold = as.factor(iowa2$YrSold)

# Convert to categorical TEST set
TEST$MSSubClass = as.character(TEST$MSSubClass)
TEST$MoSold = as.character(TEST$MoSold)
TEST$YrSold = as.character(TEST$YrSold)
```

```{r}
# Change "C (all)" to "C"
iowa[iowa$MSZoning == "C (all)", ]$MSZoning = "C"

iowa2[iowa2$MSZoning == "C (all)", ]$MSZoning = "C"

TEST[TEST$MSZoning == "C (all)", ]$MSZoning = "C"
```

```{r}
# finding number of NA's in each column
apply(TEST, 2, function(x) sum(is.na(x)))
```

```{r}
# checking the TEST set for missingness

for (name in colnames(TEST)) {
    if (class(TEST[[name]]) == "character") {
        print(name)
        print(table(TEST[[name]]))
        cat("number missing:", as.character(sum(is.na(TEST[[name]]))), "\n")
        print("-------------------")
    }
}
```

```{r}
# evaluating the missingness

hist(TEST$WoodDeckSF)
hist(log(TEST$WoodDeckSF + 1))

range(iowa$MasVnrArea)

nrow(iowa[TEST$MiscVal == 0, ])/1460*100

which(is.na(TEST$FullBath))

TEST[is.na(TEST$BsmtQual), ]

mean(TEST$TotalBsmtSF, na.rm = T)
```

```{r}
mean(TEST$GarageArea, na.rm = T)
```

```{r}
# impute LotFrontage to median of neighborhood and then transforming
iowa = iowa %>% 
    group_by(Neighborhood) %>% 
    mutate(LotFrontage = replace(LotFrontage, is.na(LotFrontage), median(LotFrontage, na.rm = T))) %>% ungroup()
iowa$LotFrontage = log(iowa$LotFrontage + 1)

iowa2 = iowa2 %>% 
    group_by(Neighborhood) %>% 
    mutate(LotFrontage = replace(LotFrontage, is.na(LotFrontage), median(LotFrontage, na.rm = T))) %>% ungroup()
iowa2$LotFrontage = log(iowa2$LotFrontage + 1)

TEST = TEST %>% 
    group_by(Neighborhood) %>% 
    mutate(LotFrontage = replace(LotFrontage, is.na(LotFrontage), median(LotFrontage, na.rm = T))) %>% ungroup()
TEST$LotFrontage = log(TEST$LotFrontage + 1)
```

```{r}
# log transforming variables with lots of zeros
iowa$LotArea = log(iowa$LotArea + 1)
iowa$BsmtFinSF1 = log(iowa$BsmtFinSF1 + 1)
iowa$TotalBsmtSF = log(iowa$TotalBsmtSF + 1)
iowa$X2ndFlrSF = log(iowa$X2ndFlrSF + 1)
iowa$GarageArea = log(iowa$GarageArea + 1)
iowa$WoodDeckSF = log(iowa$WoodDeckSF + 1)
iowa$OpenPorchSF = log(iowa$OpenPorchSF + 1)
iowa$EnclosedPorch = log(iowa$EnclosedPorch + 1)
iowa$ScreenPorch = log(iowa$ScreenPorch + 1)
iowa$BsmtUnfSF = log(iowa$BsmtUnfSF + 1)

iowa2$LotArea = log(iowa2$LotArea + 1)
iowa2$BsmtFinSF1 = log(iowa2$BsmtFinSF1 + 1)
iowa2$TotalBsmtSF = log(iowa2$TotalBsmtSF + 1)
iowa2$X2ndFlrSF = log(iowa2$X2ndFlrSF + 1)
iowa2$GarageArea = log(iowa2$GarageArea + 1)
iowa2$WoodDeckSF = log(iowa2$WoodDeckSF + 1)
iowa2$OpenPorchSF = log(iowa2$OpenPorchSF + 1)
iowa2$EnclosedPorch = log(iowa2$EnclosedPorch + 1)
iowa2$ScreenPorch = log(iowa2$ScreenPorch + 1)
iowa2$BsmtUnfSF = log(iowa2$BsmtUnfSF + 1)

TEST$LotArea = log(TEST$LotArea + 1)
TEST$BsmtFinSF1 = log(TEST$BsmtFinSF1 + 1)
TEST$TotalBsmtSF = log(TEST$TotalBsmtSF + 1)
TEST$X2ndFlrSF = log(TEST$X2ndFlrSF + 1)
TEST$GarageArea = log(TEST$GarageArea + 1)
TEST$WoodDeckSF = log(TEST$WoodDeckSF + 1)
TEST$OpenPorchSF = log(TEST$OpenPorchSF + 1)
TEST$EnclosedPorch = log(TEST$EnclosedPorch + 1)
TEST$ScreenPorch = log(TEST$ScreenPorch + 1)
TEST$BsmtUnfSF = log(TEST$BsmtUnfSF + 1)
```

```{r}
# imputing missing FinType
iowa$BsmtFinType2[333] = "GLQ"

iowa2$BsmtFinType2[333] = "GLQ"
```

```{r}
# imputing single missing variable
iowa$Electrical[1380] = "SBrkr"

iowa2$Electrical[1380] = "SBrkr"
```

```{r}
# imputing NA's where the variable is actually lacking in the house
# and not due to missingness
categorical = c("MSSubClass", "MSZoning", "Street", "Alley", "LotShape", 
               "LandContour", "Utilities", "LotConfig", "LandSlope", "Neighborhood", 
               "Condition1", "Condition2", "BldgType", "HouseStyle", "RoofStyle",
               "RoofMatl", "Exterior1st", "Exterior2nd", "MasVnrType", "ExterQual",
               "ExterCond", "Foundation", "BsmtQual", "BsmtCond", "BsmtExposure",
               "BsmtFinType1", "BsmtFinType2", "Heating", "HeatingQC", "CentralAir",
               "Electrical", "KitchenQual", "Functional", "FireplaceQu", "GarageType",
               "GarageFinish", "GarageQual", "GarageCond", "PavedDrive", "PoolQC", 
               "Fence", "MiscFeature", "SaleType", "SaleCondition")

for (c in categorical){
    iowa[[c]] = as.character(iowa[[c]])
    iowa[[c]][is.na(iowa[[c]])] = "Absent"
    iowa[[c]] = as.factor(iowa[[c]])
}

for (c in categorical){
    iowa2[[c]] = as.character(iowa2[[c]])
    iowa2[[c]][is.na(iowa2[[c]])] = "Absent"
    iowa2[[c]] = as.factor(iowa2[[c]])
}


```

```{r}
# Change "None" class to "Absent"
iowa[iowa$MasVnrType == "None", ]$MasVnrType = "Absent"

iowa2[iowa2$MasVnrType == "None", ]$MasVnrType = "Absent"

TEST[TEST$MasVnrType == "None", ]$MasVnrType = "Absent"
```

```{r}
# imputing NA's to zeros
# log transforming for the zeros
iowa = iowa %>% 
    mutate(MasVnrArea = replace(MasVnrArea, is.na(MasVnrArea), 0))
iowa$MasVnrArea = log(iowa$MasVnrArea + 1)

iowa2 = iowa2 %>% 
    mutate(MasVnrArea = replace(MasVnrArea, is.na(MasVnrArea), 0))
iowa2$MasVnrArea = log(iowa2$MasVnrArea + 1)

TEST = TEST %>% 
    mutate(MasVnrArea = replace(MasVnrArea, is.na(MasVnrArea), 0))
TEST$MasVnrArea = log(TEST$MasVnrArea + 1)
```

```{r}
# changing Garage Year Built to a yes/no category
iowa$GarageYrBlt[is.na(iowa$GarageYrBlt)] = 0
iowa$GarageYrBlt = ifelse(iowa$GarageYrBlt > 0, 1, 0)
iowa$GarageYrBlt = as.factor(iowa$GarageYrBlt)

iowa2$GarageYrBlt[is.na(iowa2$GarageYrBlt)] = 0
iowa2$GarageYrBlt = ifelse(iowa2$GarageYrBlt > 0, 1, 0)
iowa2$GarageYrBlt = as.factor(iowa2$GarageYrBlt)

TEST$GarageYrBlt[is.na(TEST$GarageYrBlt)] = 0
TEST$GarageYrBlt = ifelse(TEST$GarageYrBlt > 0, 1, 0)
TEST$GarageYrBlt = as.factor(TEST$GarageYrBlt)
```

```{r}
# dropping the following categories
iowa = iowa %>% select(-c(Street, Alley, Utilities, Condition2, RoofMatl, BsmtFinSF2, LowQualFinSF, Functional,
                   X3SsnPorch, PoolArea, PoolQC, MiscFeature, MiscVal))

iowa2 = iowa2 %>% select(-c(Street, Alley, Utilities, Condition2, RoofMatl, BsmtFinSF2, LowQualFinSF, Functional,
                   X3SsnPorch, PoolArea, PoolQC, MiscFeature, MiscVal, LandContour,
                   LandSlope, ExterCond, BsmtCond, BsmtFinType2, BsmtUnfSF,
                   Heating))

TEST = TEST %>% select(-c(Street, Alley, Utilities, Condition2, RoofMatl, BsmtFinSF2, LowQualFinSF, Functional,
                   X3SsnPorch, PoolArea, PoolQC, MiscFeature, MiscVal))
```

```{r}
# logging our varialbe
iowa$SalePrice = log(iowa$SalePrice + 1)

iowa2$SalePrice = log(iowa2$SalePrice + 1)

TEST$SalePrice = log(TEST$SalePrice + 1)
```

```{r}
# separating categorical and numerical features to scale numerics
cat = iowa[c(1, 2, 5:12, 17:20, 22:28, 30, 33:36, 46, 49:52, 55:57, 62:66)]
scaled = as.data.frame(apply(iowa[c(3, 4, 13:16, 21, 29, 31, 32, 37:45, 47, 48, 53, 54, 58:61)], 2, scale))
SalePrice = iowa$SalePrice

iowa_scaled = cbind(cbind(cat, scaled), SalePrice)
iowa_dummied = as.data.frame(model.matrix(SalePrice ~., data = iowa)[, -1])
```


FINISHED CLEANING DATA HERE


```{r}
# splitting data 80/20 for testing/training
set.seed(0)
train_indices = sample(1:nrow(iowa), 8*nrow(iowa)/10)

iowa_train = iowa[train_indices, ]
iowa_test = iowa[-train_indices, ]

iowa2_train = iowa2[train_indices, ]
iowa2_test = iowa2[-train_indices, ]

iowa_train_scaled = iowa_scaled[train_indices, ]
iowa_test_scaled = iowa_scaled[-train_indices, ]

iowa_train_dummied = iowa_dummied[train_indices, ]
iowa_test_dummied = iowa_dummied[-train_indices, ]

dummy_train_price = iowa_scaled$SalePrice[train_indices]
dummy_test_price = iowa_scaled$SalePrice[-train_indices]

abcd = read.csv("train_clean.csv")

abcd$SalePrice = log(abcd$SalePrice + 1)

abcd_train = abcd[train_indices, ]
abcd_test = abcd[-train_indices, ]
```

```{r}
# library(randomForest)

set.seed(0)
oob.err = numeric(66)
for (mtry in 1:66) {
  fit = randomForest(SalePrice ~ ., data = iowa2_train, mtry = mtry)
  oob.err[mtry] = fit$mse[500] # oob error for each mtry 
  cat("We're performing iteration", mtry, "\n")
}

set.seed(0)
abcd_oob.err = numeric(64)
for (mtry in 1:64) {
  fit = randomForest(SalePrice ~ ., data = abcd_train, mtry = mtry)
  abcd_oob.err[mtry] = fit$mse[500] # oob error for each mtry 
  cat("We're performing iteration", mtry, "\n")
}

plot(1:64, oob.err, pch = 16, type = "b",
     xlab = "Variables Considered at Each Split",
     ylab = "OOB Mean Squared Error",
     main = "Random Forest OOB Error Rates\nby # of Variables")

# on the 80% training set this is the outcome
which.min(oob.err) # --> 22 variables
min(abcd_oob.err) # --> 0.01879761

# making model with num vars corresponding to lowest error
rf_iowa_best = randomForest(SalePrice ~ ., data = iowa_train, mtry = 22, importance = T)
rf_abcd_best = randomForest(SalePrice ~ ., data = abcd_train, mtry = 20, importance = T)

# predicting on 20% test set
yhat = predict(rf_iowa_best, newdata = iowa_test)
yhat_abcd = predict(rf_abcd_best, newdata = abcd_test)



rf_abcd_best

# error on the 20% test set
mean((yhat - iowa_test$SalePrice)^2) # --> 0.0212
mean((yhat_abcd - abcd_test$SalePrice)^2)

plot((exp(yhat) - 1), (exp(iowa_test$SalePrice) - 1))
abline(0, 1)

summary(lm(exp(yhat - 1) ~ exp(iowa_test$SalePrice - 1)))

rf_iowa_all = randomForest(SalePrice ~ ., data = iowa, mtry = 22, importance = T)

# training model on 100% of TRAINING set
rf_iowa_all # <--- showing these results below; mean square residuals --> 0.0191
```

```{r}
# TEST$SalePrice = 0
yhat_TEST = predict(rf_iowa_all, newdata = TEST, type = "response")
yhat = predict(rf_iowa_best, newdata = iowa_test)

TEST

str(TEST)
str(iowa)

dim(TEST)

dim(iowa)

all(apply(iowa, 2, class) == apply(TEST, 2, class))
```

```{r}
plot(1:66, oob.err, pch = 16, type = "b",
     xlab = "Variables Considered at Each Split",
     ylab = "OOB Mean Squared Error",
     main = "Random Forest OOB Error Rates\nby # of Variables")

which.min(oob.err) # --> 22 variables
min(oob.err) # --> 0.01879761

rf_iowa_best = randomForest(SalePrice ~ ., data = iowa_train, mtry = 22, importance = T)
yhat = predict(rf_iowa_best, newdata = iowa_test, type = "response")

mean((yhat - iowa_test$SalePrice)^2)

rf_iowa_all = randomForest(SalePrice ~ ., data = iowa, mtry = 22, importance = T)

rf_iowa_all #

```

```{r}
# library(caret)

lmFit = train(SalePrice ~ ., data = iowa_train, method = "lm")
lmFit = train(dummy_train_price ~ ., data = iowa_train_dummied, method = "lm")

summary(lmFit)

lmFit$finalModel$coefficients

# these were the ones with NAs in the lm
iowa_train_dummied2 = iowa_train_dummied %>% select(-c(GarageCondTA, GarageQualTA, GarageCondEx, GarageFinishUnf,
                                                       GarageYrBlt1, BsmtFinType2Unf, BsmtFinType1Unf, BsmtCondTA,
                                                       ExterCondPo, MasVnrTypeNone, Exterior2ndCBlock, 
                                                       Exterior1stAsphShn, BldgTypeDuplex))

lmFit = train(dummy_train_price ~ ., data = iowa_train_dummied2, method = "lm")

iowa_train_dummied2 %>% select

View(iowa_train_dummied2)

iowa %>% select(-c(MSZoning, LotFrontage))

dummy_train_price

```


```{r}
alias(lmFit)

mse = mean(residuals(lmFit)^2)
mse
rsme = sqrt(mse)
rsme
```

```{r}
varImp(lmFit, scale = F)
```

```{r}
mean(lmFit$resample$RMSE)
```

```{r}
predicted = predict(lmFit, iowa_test)
RMSE(pred = predicted, obs = iowa_test$SalePrice)
```

```{r}
set.seed(456)
fitCtrl <- trainControl(method = "cv",
                        number = 10)
```

```{r}
enetGrid = expand.grid(alpha = seq(0, 1, .1),
                       lambda = seq(0, 0.6, 0.01))

set.seed(0)
enetFit = train(SalePrice ~ .,
                data = iowa_train,
                method = "glmnet",
                metric = "RMSE",
                trControl = fitCtrl,
                tuneGrid = enetGrid)

enetFit = train(dummy_train_price ~ .,
                data = iowa_train_dummied,
                method = "glmnet",
                metric = "RMSE",
                trControl = fitCtrl,
                tuneGrid = enetGrid)

iowa_train_scaled = iowa_scaled[train_indices, ]

sum(is.na(iowa_train))
```












